defaults:
  # Set these defaults inside `ray_tune_run_kwargs`
  - scheduler@ray_tune_run_kwargs.scheduler: pbt
  - search_space@ray_tune_run_kwargs.config: autolfads_default
  # Use colored logger
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog
  - _self_

run_tag: ???
runs_home: /snel/share/runs/lfads-torch/testing
config_train: pbt_train.yaml
local_mode: False
overwrite: True

ray_tune_run_kwargs:
  name: ${run_tag}
  metric: valid/recon_smth
  mode: min
  resources_per_trial:
    cpu: 3
    gpu: 0.5
  search_alg:
    _target_: ray.tune.suggest.basic_variant.BasicVariantGenerator
    random_state: 0
  trial_dirname_creator:
    _target_: lfads_torch.tune_utils.get_trial_dirname_creator
  num_samples: 20
  progress_reporter:
    _target_: ray.tune.CLIReporter
    metric_columns:
      - valid/recon_smth
      - cur_epoch
    sort_by_metric: True
  # With `name`, a hack to get `ray.tune` to use the directory created by `hydra`.
  local_dir: ".."
  verbose: 1
  reuse_actors: True
  keep_checkpoints_num: 1
  # stop:
  #   _target_: ray.tune.stopper.ExperimentPlateauStopper
  #   metric: valid/recon_smth
  #   std: 1.0e-5
  #   top: 10
  #   patience: 100

hydra:
  run:
    dir: ${runs_home}/pbt/${run_tag}
  output_subdir: null
