defaults:
  - model: nlb_mc_rtt
  - datamodule: nlb_mc_rtt
  - callbacks: nlb
  # enable color logging
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog
  - _self_

seed: 0
ignore_warnings: True

trainer:
  _target_: pytorch_lightning.Trainer
  gradient_clip_val: 200
  max_epochs: 1_000
  log_every_n_steps: 5
  # Checkpointing is managed by the `TuneReportCheckpointCallback`
  enable_checkpointing: False
  # Prevent console output by individual models
  enable_progress_bar: False
  enable_model_summary: False

# Allow PBT to handle LR scheduling
model:
  lr_decay: 0.99999

callbacks:
  tune_report_checkpoint_callback:
    _target_: ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback
    metrics:
      - valid/recon_smth
      - cur_epoch
    filename: tune.ckpt
    "on": validation_end
  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: epoch

posterior_sampling:
  best_ckpt: false
  fn:
    _target_: lfads_torch.post_run.analysis.run_posterior_sampling
    filename: lfads_output.h5
    num_samples: 50

logger:
  csv_logger:
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: "csv_logs"
    # Allow the logger to create a new version for each generation
    version: null
    name: ""
